---
layout: post
title: "Load Testing HAProxy (Part 2)"
comments: True
---

<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Load Testing HAProxy (Part 2)</title><style>
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 100%;
        margin: auto;
      }
      section {
        width: 100%;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 100%;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Load Testing HAProxy (Part 2)</h1>
</header>
<section data-field="subtitle" class="p-summary">
This is the second part in the 3 part series on performance testing of the famous TCP load balancer and reverse proxy, HAProxy. If you…
</section>
<section data-field="body" class="e-content">
<section name="c817" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="541b" id="541b" class="graf graf--h3 graf--leading graf--title"></h3></div><div class="section-inner sectionLayout--fullWidth"><figure name="6ced" id="6ced" class="graf graf--figure graf--layoutFillWidth graf-after--h3"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 72.7%;"></div><img class="graf-image" data-image-id="1*s2S16ZXbIxtsYIG87aOadg.png" data-width="3055" data-height="2222" src="https://cdn-images-1.medium.com/max/2000/1*s2S16ZXbIxtsYIG87aOadg.png"></div></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="2b00" id="2b00" class="graf graf--p graf-after--figure">This is the second part in the 3 part series on performance testing of the famous TCP load balancer and reverse proxy, HAProxy. If you haven’t gone through the previous post, I would highly suggest you do so to get some sort of context.</p><div name="11c5" id="11c5" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@sachinmalhotra/load-testing-haproxy-part-1-f7d64500b75d" data-href="https://medium.com/@sachinmalhotra/load-testing-haproxy-part-1-f7d64500b75d" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@sachinmalhotra/load-testing-haproxy-part-1-f7d64500b75d"><strong class="markup--strong markup--mixtapeEmbed-strong">Load Testing HAProxy (Part-1)</strong><br><em class="markup--em markup--mixtapeEmbed-em">Load Testing ? HAProxy ? If all this seems greek to you, don’t worry. I will provide inline links to read up on what…</em>medium.com</a><a href="https://medium.com/@sachinmalhotra/load-testing-haproxy-part-1-f7d64500b75d" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="b4e074c36e4fe03700883e589ab06de8" data-thumbnail-img-id="1*4npSurj6b2n__CsxxnaUQw.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*4npSurj6b2n__CsxxnaUQw.png);"></a></div><p name="834b" id="834b" class="graf graf--p graf-after--mixtapeEmbed">This post will focus on the TCP Port exhaustion problem and how we can deal with it. In the last post we talked about how we can tune the kernel level and process level ulimit settings. This post is focussed on modifying the sysctl settings to get over the port exhaustion limits.</p><h3 name="ebc3" id="ebc3" class="graf graf--h3 graf-after--p">SYSCTL Local Port Range and Orphaned Sockets</h3><p name="ade3" id="ade3" class="graf graf--p graf-after--h3">Port exhaustion is a problem that will cause TCP communications with other machines over the network to fail. Most of the times there is a single process that leads to this problem and restarting it will fix the issue, temporarily. It will however come back to bite in a few hours or days depending on the system load.</p><p name="1eac" id="1eac" class="graf graf--p graf-after--p">Port exhaustion does not mean that the ports actually get tired. Of course, that is not possible because the computer is not human and the ports are not capable of getting tired. The truth is much more insidious. Port exhaustion simply means that the system does not have any more <em class="markup--em markup--p-em">ephemeral ports </em>left to communicate with other machines / servers.</p><p name="b353" id="b353" class="graf graf--p graf-after--p">Before going further, <em class="markup--em markup--p-em">let us understand what constitutes a TCP connection and what really does an inbound and an outbound connection means.</em></p><p name="4d78" id="4d78" class="graf graf--p graf-after--p">In majority of the cases whenever we talk about TCP connections and high scalability and ability to support concurrent connections, we usually refer to the number of inbound connections.</p><p name="12a7" id="12a7" class="graf graf--p graf-after--p">Say, the HAProxy is listening on port 443 for new inbound connections. If we say that the HAProxy can support X number of concurrent connections, what we really mean are X number of incoming connections and all of them are established on port 443 on the HAProxy machine.</p><p name="e89e" id="e89e" class="graf graf--p graf-after--p">If these connections are inbound for the HAProxy, then these have to be <em class="markup--em markup--p-em">outbound for the client machines where the connection originated. </em>Any sort of communication from the client requires them to initiate outbound connections to the servers.</p><blockquote name="370e" id="370e" class="graf graf--blockquote graf-after--p">When a connection is established over TCP, a socket is created on both the local and the remote host. These sockets are then connected to create a socket pair, which is described by a unique 4-tuple consisting of the local IP address and port along with the remote IP address and port.</blockquote><figure name="d060" id="d060" class="graf graf--figure graf-after--blockquote"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 222px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 31.8%;"></div><img class="graf-image" data-image-id="1*RTMxj2dEaOP0jxRS0II52Q.png" data-width="1410" data-height="448" src="https://cdn-images-1.medium.com/max/800/1*RTMxj2dEaOP0jxRS0II52Q.png"></div><figcaption class="imageCaption">3 TCP connections from client to server/proxy</figcaption></figure><p name="671f" id="671f" class="graf graf--p graf-after--figure">If you understood the concept of the quadruple, you will realise that in an outbound connection or rather multiple outbound connections to the SAME backend server, 2things always remain the same i.e. Destination IP and Destination Port. Assuming we are only taking into account a single client machine, the client IP will also remain the same.</p><p name="69b3" id="69b3" class="graf graf--p graf-after--p">This means that the number of outbound connections is dependent on the number of client ports that can be used for establishing the connection. While establishing an outbound connection, the source port is randomly selected from the ephemeral port range and this port gets freed up once the connection is destroyed. That’s why such ports are called as ephemeral ports.</p><p name="1a97" id="1a97" class="graf graf--p graf-after--p">By default, the total number of local ephemeral ports available are around 28000.</p><figure name="93c0" id="93c0" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 55px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 7.9%;"></div><img class="graf-image" data-image-id="1*wizxu4JbP_-59HRWOxNTbg.png" data-width="1036" data-height="82" src="https://cdn-images-1.medium.com/max/800/1*wizxu4JbP_-59HRWOxNTbg.png"></div></figure><p name="a382" id="a382" class="graf graf--p graf-after--figure">Now you might be thinking that 28k is a pretty large number and what can possibly cause 28k connections to get used up at a single point of time? In order to understand this, <strong class="markup--strong markup--p-strong">we have to understand the TCP connection lifecycle.</strong></p><p name="a8d1" id="a8d1" class="graf graf--p graf-after--p">During the TCP handshake, the connection state goes from</p><p name="1201" id="1201" class="graf graf--p graf-after--p">SYN_SENT → SYN_RECV → ESTABLISHED. Once the connection is in ESTABLISHED state, it means that the TCP connection is now active. <em class="markup--em markup--p-em">However, once the connection is terminated, </em>the local port that was being used earlier does not become active immediately.</p><p name="b22d" id="b22d" class="graf graf--p graf-after--p">The connection enters a state known as the <em class="markup--em markup--p-em">TIME_WAIT state for a period of 120 seconds before it is finally terminated. </em>This is a kernel level setting that exists to allow any delayed or out of order packets to be ignored by the network.</p><blockquote name="42e3" id="42e3" class="graf graf--blockquote graf-after--p">If you do the math, it won’t take more than<strong class="markup--strong markup--blockquote-strong"> 230 concurrent connections per second</strong> before the supposedly large limit of 28000 ephemeral ports on the system is reached. This limit is very easy to reach on proxies like HAProxy or NGINX because all the traffic is routed through them to the backend servers.</blockquote><p name="cf20" id="cf20" class="graf graf--p graf-after--blockquote">When a connection enters the TIME_WAIT state, it is known as an <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">orphaned socket</em></strong> because the TCP socket in this case is not help by any socket descriptor but are still held by the system for the designated time i.e. 120 seconds by default.</p><h3 name="8aa2" id="8aa2" class="graf graf--h3 graf-after--p">How to detect this?</h3><p name="c7d5" id="c7d5" class="graf graf--p graf-after--h3">Enough with all the theoretical stuff. Let’s jump in and see how we can identify if this limit has been hit on the system. There are two commands I absolutely love to use to find out the number of TCP connections established on the system.</p><h4 name="39b4" id="39b4" class="graf graf--h4 graf-after--p">ss (Socket Statistics)</h4><p name="b0bb" id="b0bb" class="graf graf--p graf-after--h4">The socket statistics command is a sort of replacement of the famous netstat command and is much faster than the netstat command in rendering information because it fetches the connections info directly from the kernel space. In order to get a hang of the different options supported by the ss command, check out</p><div name="da84" id="da84" class="graf graf--mixtapeEmbed graf-after--p"><a href="http://www.binarytides.com/linux-ss-command/" data-href="http://www.binarytides.com/linux-ss-command/" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://www.binarytides.com/linux-ss-command/"><strong class="markup--strong markup--mixtapeEmbed-strong">10 examples of Linux ss command to monitor network connections</strong><br><em class="markup--em markup--mixtapeEmbed-em">In a previous tutorial we saw how to use the netstat command to get statistics on network/socket connections. However…</em>www.binarytides.com</a><a href="http://www.binarytides.com/linux-ss-command/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="d00df2553001213c2bb541f65e1b78eb" data-thumbnail-img-id="0*CzGSu58bgHL_QyV1." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*CzGSu58bgHL_QyV1.);"></a></div><p name="5ca3" id="5ca3" class="graf graf--p graf-after--mixtapeEmbed">The `ss -s` command will show the total number of TCP established connections on the machine. If you see this reach the 28000 mark, it is very much possible that the ephemeral ports have been exhausted on that machine. <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">BEWARE:</em></strong> This might be higher than the 28k number if multiple services are running on the same machine on different ports.</p><h4 name="8c67" id="8c67" class="graf graf--h4 graf-after--p">Netstat</h4><p name="3776" id="3776" class="graf graf--p graf-after--h4">The netstat command is a very famous command that provides information about all sorts of connections established on the machine’s networking stack.</p><pre name="2578" id="2578" class="graf graf--pre graf-after--p">sudo netstat -anptl </pre><p name="9e98" id="9e98" class="graf graf--p graf-after--pre">This will show you the details about all the connections on the machine. The details include</p><ul class="postList"><li name="1504" id="1504" class="graf graf--li graf-after--p">local address</li><li name="056f" id="056f" class="graf graf--li graf-after--li">remote address</li><li name="132e" id="132e" class="graf graf--li graf-after--li">connection state</li><li name="7508" id="7508" class="graf graf--li graf-after--li">process pid</li></ul><p name="59f8" id="59f8" class="graf graf--p graf-after--li">We can also use this to see if a single process has established 28k connections to an outbound server which gives us insights into the port exhaustion problem.</p><figure name="3bb6" id="3bb6" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 200px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.499999999999996%;"></div><img class="graf-image" data-image-id="1*sZemeif4fRCVwE56TnP44A.png" data-width="1486" data-height="424" src="https://cdn-images-1.medium.com/max/800/1*sZemeif4fRCVwE56TnP44A.png"></div></figure><p name="a67e" id="a67e" class="graf graf--p graf-after--figure">For eg:- the above image shows that a process with pid 9758 has established multiple connections with the foreign machine with IP 192.168.0.168 and port 443. As we can clearly see, on the source side of things, there are numerous ports being used.</p><pre name="eaae" id="eaae" class="graf graf--pre graf-after--p">sachinm@ip-192-168-0-122:~$ sudo netstat -anptl | grep &#39;192.168.0.168:443&#39; | cut -c69-79 | sort | uniq -c | sort -rn</pre><pre name="f3dd" id="f3dd" class="graf graf--pre graf-after--pre">5670 ESTABLISHED</pre><p name="5da7" id="5da7" class="graf graf--p graf-after--pre">This modified command will show the status of the different connections established with 192.168.0.168 on port 443. Currently there are 5670 connections. If this limit were to reach 28k, then you should look at options to increase the ephemeral port range on the machine.</p><p name="3ee7" id="3ee7" class="graf graf--p graf-after--p">Let’s look at another interesting command that you can issue at the server end or the proxy end to find out how many inbound connections have been established and by which IPs. So for example check out the result of the below command</p><pre name="c222" id="c222" class="graf graf--pre graf-after--p">ss -tan &#39;sport = :443&#39; | awk &#39;{print $(NF)&quot; &quot;$(NF-1)}&#39; | sed &#39;s/:[^ ]*//g&#39; | sort | uniq -c</pre><figure name="ca9b" id="ca9b" class="graf graf--figure graf-after--pre"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 256px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 36.5%;"></div><img class="graf-image" data-image-id="1*1QWzk7jbPFW_vXZ1f-M2Lw.png" data-width="2020" data-height="738" src="https://cdn-images-1.medium.com/max/800/1*1QWzk7jbPFW_vXZ1f-M2Lw.png"></div></figure><p name="f345" id="f345" class="graf graf--p graf-after--figure">This shows that there are about 14 different machines who have established around 2300 connections each with 192.168.0.168 and if you look at the command closely, we have filtered out results only for port 443.</p><p name="7e0d" id="7e0d" class="graf graf--p graf-after--p">Enough with finding the problem already. Let’s dive straight into finding the solution(s) to this problem.</p><h3 name="f22f" id="f22f" class="graf graf--h3 graf-after--p">What’s the way out?</h3><figure name="aec5" id="aec5" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 700px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 100%;"></div><img class="graf-image" data-image-id="1*KhacIUhbHawI68R-IRyD8A.png" data-width="960" data-height="960" src="https://cdn-images-1.medium.com/max/800/1*KhacIUhbHawI68R-IRyD8A.png"></div></figure><p name="68fb" id="68fb" class="graf graf--p graf-after--figure">Well don’t be afraid because sysctl just happens to be a friendly monster. There are many ways by which we can solve this problem.</p><h4 name="a197" id="a197" class="graf graf--h4 graf-after--p">Approach #1</h4><p name="d6fa" id="d6fa" class="graf graf--p graf-after--h4">One of the most practical approaches to solve this problem and one that you most likely will or rather should end up doing is to increase the local ephemeral port range to the maximum possible value. As mentioned before, the default range is very small.</p><pre name="34e5" id="34e5" class="graf graf--pre graf-after--p">echo 1024 65535 &gt; /proc/sys/net/ipv4/ip_local_port_range</pre><p name="cc9d" id="cc9d" class="graf graf--p graf-after--pre">This will increase the local port range to a bigger value. We cannot increase the range beyond this as there can only be a maximum of 65535 ports and the first 1024 are reserved for select services and purposes.</p><p name="930e" id="930e" class="graf graf--p graf-after--p">Note that you might still get bottleneck on this issue. However, instead of 28000 ports being used locally, it will be 64000 ports. Not a full proof solution but this is something that you can do to give you some breathing room.</p><p name="d6ea" id="d6ea" class="graf graf--p graf-after--p">Does this mean I can only get about 64k concurrent connections from a single client machine? The answer is NO.</p><figure name="d99a" id="d99a" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 436px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 62.3%;"></div><img class="graf-image" data-image-id="1*SURvNQCUrxJ0KMyhii6uGQ.png" data-width="1550" data-height="966" src="https://cdn-images-1.medium.com/max/800/1*SURvNQCUrxJ0KMyhii6uGQ.png"></div></figure><p name="3fbc" id="3fbc" class="graf graf--p graf-after--figure">In this scenario, a single client machine will be able to generate about 120k concurrent connections because both the processes are connecting to two different backend servers or proxies and hence different destination IPs.</p><h4 name="cc97" id="cc97" class="graf graf--h4 graf-after--p">Approach #2</h4><p name="daa1" id="daa1" class="graf graf--p graf-after--h4">Another simple solution is to enable a Linux TCP option called <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">tcp_tw_reuse. </em></strong>This option enables the Linux kernel to reclaim a connection slot from a connection in TIME_WAIT state and reallocate it to a new connection.</p><pre name="430a" id="430a" class="graf graf--pre graf-after--p">--&gt; vim /etc/sysctl.conf</pre><pre name="d9c7" id="d9c7" class="graf graf--pre graf-after--pre">--&gt; <strong class="markup--strong markup--pre-strong">Add the following line in the end</strong><br># Allow reuse of sockets in TIME_WAIT state for new connections<br># only when it is safe from the network stack’s perspective.<br>net.ipv4.tcp_tw_reuse = 1</pre><pre name="491e" id="491e" class="graf graf--pre graf-after--pre">--&gt; <strong class="markup--strong markup--pre-strong">Reload sysctl settings<br></strong>sysctl -p</pre><h4 name="dd82" id="dd82" class="graf graf--h4 graf-after--pre">Approach #3</h4><p name="2d46" id="2d46" class="graf graf--p graf-after--h4">Use more server ports. Till now we have talked about port exhaustion problems arising because in the quadruplet logic discussed before, the destination Ip, destination port and source Ip remain constant. The only thing that changes is the client ports.</p><p name="3f86" id="3f86" class="graf graf--p graf-after--p">However, if the server listens on two different ports instead of one, then we have twice the number of ephemeral ports available instead of one. This clubbed with the first approach gives you about 120k concurrent connections on a single machine.</p><p name="d739" id="d739" class="graf graf--p graf-after--p">You have to however take care that running the server on two ports — which essentially means running two servers on the same machine — does not have a huge impact on the hardware.</p><h4 name="0e97" id="0e97" class="graf graf--h4 graf-after--p">Approach #4</h4><p name="59d0" id="59d0" class="graf graf--p graf-after--h4">In a real production scenario, you may have millions of concurrent users simultaneously hitting the system. But in a load testing scenario, these users are to be artificially generated by a client running on a machine.</p><p name="5f91" id="5f91" class="graf graf--p graf-after--p">Here again the 65k port limit comes to bite on the client side. The only way to overcome this from the client’s perspective is to increase the number of client machines that are generating the load. As you will read the next part in this series you will find that we had to use about 14 different machines to generate the kind of load we wanted to test HAProxy.</p><h3 name="6722" id="6722" class="graf graf--h3 graf-after--p">Putting it all together</h3><p name="0e45" id="0e45" class="graf graf--p graf-after--h3">There isn’t one single configuration that will solve all your woes and work like a charm. It is always the combination of multiple things that work out in the end.</p><p name="a687" id="a687" class="graf graf--p graf-after--p">For us as a prerequisite to load testing HAProxy, we followed approach #1 and approach #2 and eventually approach #3 to generate a huge…huge load of <strong class="markup--strong markup--p-strong">2 million concurrent connections</strong> on a single HAProxy machine.</p><p name="7584" id="7584" class="graf graf--p graf-after--p"><a href="https://medium.freecodecamp.com/how-we-fine-tuned-haproxy-to-achieve-2-000-000-concurrent-ssl-connections-d017e61a4d27" data-href="https://medium.freecodecamp.com/how-we-fine-tuned-haproxy-to-achieve-2-000-000-concurrent-ssl-connections-d017e61a4d27" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Here’s the final part of this series</a>, where I’ll put together all the components that went into generating this kind of load, the tunings we did and the learnings that came out of it.</p><p name="3958" id="3958" class="graf graf--p graf-after--p graf--trailing">Do let me know how this blog post helped you and stay tuned for the final part in this series of posts. Also, please recommend (❤) this post if you think this may be useful for someone.</p></div></div></section>
</section>
</article></body></html>

---
layout: post
title: "Load Testing HAProxy (Part 1)"
---

<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Load Testing HAProxy (Part 1)</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 100%;
        margin: auto;
      }
      section {
        width: 100%;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 100%;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Load Testing HAProxy (Part 1)</h1>
</header>
<section data-field="subtitle" class="p-summary">
This is the first post in a 3 part series on load testing HAProxy, which is a reliable, high performant TCP/HTTP load balancer.
</section>
<section data-field="body" class="e-content">
<section name="32f4" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="f5c9" id="f5c9" class="graf graf--h3 graf--leading graf--title"></h3></div><div class="section-inner sectionLayout--fullWidth"><figure name="d9b7" id="d9b7" class="graf graf--figure graf--layoutFillWidth graf-after--h3"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><img class="graf-image" data-image-id="1*cj6DXYTZl0q9RDR-3mil7g.jpeg" data-width="1125" data-height="750" src="https://cdn-images-1.medium.com/max/2000/1*cj6DXYTZl0q9RDR-3mil7g.jpeg"></div></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="33bc" id="33bc" class="graf graf--p graf-after--figure">This is the first post in a 3 part series on load testing HAProxy, which is a reliable, high performant TCP/HTTP load balancer.</p><p name="abe4" id="abe4" class="graf graf--p graf-after--p">Load Testing? HAProxy? If all this seems greek to you, don’t worry. I will provide inline links to read up on everything I’m talking about in this blog post.</p><p name="c2aa" id="c2aa" class="graf graf--p graf-after--p">For reference, our current stack is:</p><ul class="postList"><li name="71cf" id="71cf" class="graf graf--li graf-after--p">Instances hosted on <a href="https://aws.amazon.com/ec2/" data-href="https://aws.amazon.com/ec2/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Amazon EC2</a> (not that this one should matter)</li><li name="7cfe" id="7cfe" class="graf graf--li graf-after--li">Ubuntu 14.04 (Trusty) for the OS</li><li name="a566" id="a566" class="graf graf--li graf-after--li"><a href="http://supervisord.org/" data-href="http://supervisord.org/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Supervisor</a> for process management</li></ul><p name="a8ed" id="a8ed" class="graf graf--p graf-after--li">On production, we have around 30-odd <a href="https://serversforhackers.com/load-balancing-with-haproxy" data-href="https://serversforhackers.com/load-balancing-with-haproxy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">HAProxy</a> load balancers that help us route our traffic to the backend servers which are in an autoscaling mode and hence don’t have a fixed number. Number of backend servers ranges from 12–32 throughout the day.</p><p name="5f2b" id="5f2b" class="graf graf--p graf-after--p"><a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts" data-href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">This article</a> should help you get up-to-speed on the basics of load balancing and how it works with HAProxy. It will also explain what routing algorithms are available.</p><p name="2b7b" id="2b7b" class="graf graf--p graf-after--p">Coming back to our topic at hand, which is load testing HAProxy.</p><p name="00b5" id="00b5" class="graf graf--p graf-after--p">Never before did we put any dedicated effort in finding out the limits of our HAProxy setup in handling HTTP and HTTPs requests. Currently, on production, we have 4 core, 30 Gig instances of HAProxy machines.</p><div name="d45f" id="d45f" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://aws.amazon.com/about-aws/whats-new/2016/11/introducing-amazon-ec2-r4-instances-the-next-generation-of-memory-optimized-instances/" data-href="https://aws.amazon.com/about-aws/whats-new/2016/11/introducing-amazon-ec2-r4-instances-the-next-generation-of-memory-optimized-instances/" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://aws.amazon.com/about-aws/whats-new/2016/11/introducing-amazon-ec2-r4-instances-the-next-generation-of-memory-optimized-instances/"><strong class="markup--strong markup--mixtapeEmbed-strong">Introducing Amazon EC2 R4 Instances, the next generation of memory-optimized instances</strong><br><em class="markup--em markup--mixtapeEmbed-em">You can now launch R4 instances, the next generation of Amazon EC2 Memory Optimized instances, featuring a larger…</em>aws.amazon.com</a><a href="https://aws.amazon.com/about-aws/whats-new/2016/11/introducing-amazon-ec2-r4-instances-the-next-generation-of-memory-optimized-instances/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="3df49ed9af24d838369e3d1069271f44" data-thumbnail-img-id="0*wwyTimwAps6HvAiJ." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*wwyTimwAps6HvAiJ.);"></a></div><p name="1f7b" id="1f7b" class="graf graf--p graf-after--mixtapeEmbed">As I am writing this post, we’re in the process of moving our entire traffic (HTTP) to HTTPs (that is, encrypted traffic). But before moving further, we needed some definitive answers to the following questions:</p><ol class="postList"><li name="3589" id="3589" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">What is the impact as we shift our traffic from Non-SSL to SSL?</strong> CPU should definitely take a hit because SSL handshake is not a normal 3 way handshake, it is rather a 5 way handshake and after the handshake is complete, further communication is encrypted using the secret key generated during the handshake and this is bound to take up CPU.</li><li name="0455" id="0455" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">What are some other hardware/software limits that might be reached on production as a result of SSL termination at the HAProxy level</strong>. We could also go for the SSL PassThrough option provided by HAProxy which terminates/decrypts the SSL connection at the backend servers. However, SSL termination at the HAProxy level is more performant and so this is what we intend to test.</li><li name="9718" id="9718" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">What is the best hardware required on production to support the kind of load that we see today</strong>. Will the existing hardware scale or do we need bigger machines? This was also one of the prime questions we wanted an answer to via this test.</li></ol><p name="872c" id="872c" class="graf graf--p graf-after--li">For this purpose we put in a dedicated effort for load testing HAProxy version 1.6 to find out answers to the above questions. I won’t be outlining the approach we took nor will I be outlining the results of this exercise in this blog post.</p><p name="4c8e" id="4c8e" class="graf graf--p graf-after--p">Rather, I will be discussing an important aspect of any load testing exercise that most of us tend to ignore.</p><h3 name="65af" id="65af" class="graf graf--h3 graf-after--p">The Ulimiter</h3><p name="7595" id="7595" class="graf graf--p graf-after--h3">If you have ever done any kind of load testing or hosted any server serving a lot of concurrent requests, you definitely would have run into the dreaded <em class="markup--em markup--p-em">“Too many open files”</em> issue.</p><figure name="ec91" id="ec91" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 400px; max-height: 398px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 99.5%;"></div><img class="graf-image" data-image-id="1*4npSurj6b2n__CsxxnaUQw.png" data-width="400" data-height="398" src="https://cdn-images-1.medium.com/max/800/1*4npSurj6b2n__CsxxnaUQw.png"></div></figure><p name="c0b6" id="c0b6" class="graf graf--p graf-after--figure">An important part of any stress testing exercise is the ability of your load testing client to establish a lot of concurrent connections to your backend server or to the proxy like HAProxy in between.</p><p name="7408" id="7408" class="graf graf--p graf-after--p">A lot of times we end up being bottleneck on the client not being able to generate the amount of load we expect it to generate. The reason for this is not because the client is not performing optimally, but something else entirely on the hardware level.</p><p name="063f" id="063f" class="graf graf--p graf-after--p">Ulimit is used to restrict the number of user level resources. For all practical purposes pertaining to load testing environments, ulimit gives us the number of file descriptors that can be opened by a single process on the system. On most machines if you check the limit on file descriptors, it comes out to be this number = <strong class="markup--strong markup--p-strong">1024.</strong></p><figure name="f449" id="f449" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 466px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.5%;"></div><img class="graf-image" data-image-id="1*qE7hD6O7lsA1RtbXwspdow.png" data-width="974" data-height="648" src="https://cdn-images-1.medium.com/max/800/1*qE7hD6O7lsA1RtbXwspdow.png"></div><figcaption class="imageCaption">Staging Ulimit Config</figcaption></figure><p name="3184" id="3184" class="graf graf--p graf-after--figure">As you can see, the number of open files is 1024 it on our staging setup. Opening a new TCP connection / socket also counts as an open file or a file descriptor and hence the limitation.</p><p name="3261" id="3261" class="graf graf--p graf-after--p">What this generally means is that a single client process can only open 1024 connections to the backend servers and no more. It means you need to increase this limit to a very high number on your load testing environment before proceeding further. Checkout the ulimit setting we have on our production machines.</p><figure name="54d3" id="54d3" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 522px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 74.6%;"></div><img class="graf-image" data-image-id="1*6QbQnvAF0m7v5OA2ko0fNw.png" data-width="866" data-height="646" src="https://cdn-images-1.medium.com/max/800/1*6QbQnvAF0m7v5OA2ko0fNw.png"></div><figcaption class="imageCaption">Production Level Ulimit config</figcaption></figure><p name="0954" id="0954" class="graf graf--p graf-after--figure">This information is what you would generally find after 10 seconds of Googling, but keep in mind that <em class="markup--em markup--p-em">ulimit is not guaranteed to give you the limits your processes actually have!</em> There’s a million things that can modify a limits of a process after (or before) you initialized your shell. So what you should do instead is fire up <code class="markup--code markup--p-code">top</code>, <code class="markup--code markup--p-code"><a href="http://hisham.hm/htop/" data-href="http://hisham.hm/htop/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">htop</a></code>, <code class="markup--code markup--p-code">ps</code>, or whatever you want to use to get the ID of the problematic process, and do a <code class="markup--code markup--p-code">cat /proc/{process_id}/limits</code>:</p><figure name="2f59" id="2f59" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 445px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 63.6%;"></div><img class="graf-image" data-image-id="1*oVCiJir-1oICfl7rxIGwfw.png" data-width="1186" data-height="754" src="https://cdn-images-1.medium.com/max/800/1*oVCiJir-1oICfl7rxIGwfw.png"></div></figure><blockquote name="e0bd" id="e0bd" class="graf graf--blockquote graf-after--figure">The max open files for this specific process is different than the system wide limits we have on this server.</blockquote><p name="3751" id="3751" class="graf graf--p graf-after--blockquote">Let’s move on to the interesting part. Raising the limits :D</p><h3 name="deb2" id="deb2" class="graf graf--h3 graf-after--p">The Stuff You Came Here to Read: Raising the Limit</h3><p name="7656" id="7656" class="graf graf--p graf-after--h3">There are two ways of changing the ulimit setting on a machine.</p><ol class="postList"><li name="54ff" id="54ff" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">ulimit -n &lt;some_value&gt;. </em></strong>This will change the ulimit settings only for the current shell session. As soon as you open another shell session, you are back to square one i.e. 1024 file descriptors. So this is probably not what you want.</li><li name="25d0" id="25d0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">fs.file-max = 500000</em></strong>. Add this line to the end of the file <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">/etc/sysctl.conf. </em></strong>And add the following<br><code class="markup--code markup--li-code">* soft nofile </code><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">500000</em></strong><code class="markup--code markup--li-code"><br>* hard nofile </code><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">500000</em></strong><code class="markup--code markup--li-code"><br>root soft nofile </code><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">500000</em></strong><code class="markup--code markup--li-code"><br>root hard nofile </code><strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">500000<br></em></strong>to the file <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">/etc/security/limits.conf.</em></strong></li></ol><p name="f517" id="f517" class="graf graf--p graf-after--li">The * basically represents that we are setting these values for all the users except root. “soft or hard” basically represent soft or hard limits. The next entry specifies the item for which we want to change the limit values i.e. nofile in this case which means the number of open files . And finally we have the value we wanna set which in this case is 500000. The * here does not apply to a root user, hence the last two lines specially for the root user.</p><p name="8ced" id="8ced" class="graf graf--p graf-after--p">After doing this, you need to take a reboot of the system. Sadly yes :( And the changes should reflect in the ulimit -n command.</p><figure name="173e" id="173e" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 79px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 11.3%;"></div><img class="graf-image" data-image-id="1*kUNMdQiWHLOilGmSNXOVZA.png" data-width="760" data-height="86" src="https://cdn-images-1.medium.com/max/800/1*kUNMdQiWHLOilGmSNXOVZA.png"></div></figure><p name="e5bf" id="e5bf" class="graf graf--p graf-after--figure">Hurray !. Pat yourself on the back. You successfully changed the ulimit settings for the system. However, it is not necessary that changing this will affect all the user processes running on the system. It is quite possible that even after changing the system wide ulimit, you might find that <em class="markup--em markup--p-em">/etc/&lt;pid&gt;/limits</em> give you a smaller number than what you might expect to find.</p><figure name="fa5b" id="fa5b" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 400px; max-height: 400px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 100%;"></div><img class="graf-image" data-image-id="1*7ZiJ5StrDzfIohN9QZeOqQ.png" data-width="400" data-height="400" src="https://cdn-images-1.medium.com/max/800/1*7ZiJ5StrDzfIohN9QZeOqQ.png"></div></figure><p name="eafa" id="eafa" class="graf graf--p graf-after--figure">In this case, you almost certainly have a process manager, or something similar that is messing up your limits. You need to keep in mind that processes inherit the limits of their parent processes. So if you have something like a Supervisor managing your processes, they will inherit the settings of the Supervisor daemon and this overrides any changes you make to the system level limits.</p><p name="4886" id="4886" class="graf graf--p graf-after--p"><a href="http://supervisord.org/configuration.html#supervisord-section-values" data-href="http://supervisord.org/configuration.html#supervisord-section-values" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Supervisor has a config variable</a> that sets the file descriptor limit of its main process. Apparently, this setting is in turn inherited by any and all processes it launches. To override the default setting, you can add the following line to <code class="markup--code markup--p-code">/etc/supervisor/supervisord.conf</code>, in the <code class="markup--code markup--p-code">[supervisord]</code>section:</p><pre name="4fcf" id="4fcf" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">minfds=500000</code></pre><p name="9aca" id="9aca" class="graf graf--p graf-after--pre">Updating this will lead to all the child processes being controlled by supervisor inheriting this updated limit. You just need to restart the supervisor daemon to bring this change into effect.</p><p name="443b" id="443b" class="graf graf--p graf-after--p">Remember to do this on any machine that intends to have a lot of concurrent connections open. Be it the client in a load testing scenario or a server trying to serve a lot of concurrent requests.</p><p name="5997" id="5997" class="graf graf--p graf-after--p"><a href="https://medium.com/p/4c8677780df6" data-href="https://medium.com/p/4c8677780df6" class="markup--anchor markup--p-anchor" target="_blank">In Part 2</a>, we’ll learn how to deal with the <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Sysctl port range monster</em></strong>.</p><p name="0e8b" id="0e8b" class="graf graf--p graf-after--p graf--trailing">Do let me know how this blog post helped you. Also, please recommend (❤) this post if you think this may be useful for someone.</p></div></div></section>
</section>
</article></body></html>